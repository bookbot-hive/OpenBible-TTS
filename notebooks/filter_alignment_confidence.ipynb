{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-12.1.0\"\n",
    "os.environ[\"PATH\"] = f\"{os.environ['CUDA_HOME']}/bin:{os.environ['PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/lib64:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/lib:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/extras/CUPTI/lib64:{os.environ['LD_LIBRARY_PATH']}'\"\n",
    "os.environ[\"CUDAToolkit_ROOT_DIR\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDAToolkit_ROOT\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "\n",
    "os.environ[\"CUDA_TOOLKIT_ROOT_DIR\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_TOOLKIT_ROOT\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_BIN_PATH\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_PATH\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_INC_PATH\"] = f\"{os.environ['CUDA_HOME']}/targets/x86_64-linux\"\n",
    "os.environ[\"CFLAGS\"] = f\"-I{os.environ['CUDA_HOME']}/targets/x86_64-linux/include:{os.environ['CFLAGS']}\"\n",
    "os.environ[\"CUDAToolkit_TARGET_DIR\"] = f\"{os.environ['CUDA_HOME']}/targets/x86_64-linux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "audio_path = Path(\"../outputs/openbible_swahili/EPH/EPH_003/EPH_003_001.wav\")\n",
    "json_path = Path(\"../data/openbible_swahili/EPH.json\")\n",
    "book, verse_id = json_path.stem, audio_path.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "from num2words import num2words\n",
    "\n",
    "def preprocess_verse(text: str) -> str:\n",
    "    text = unidecode(text)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r\"\\d+\", lambda x: num2words(int(x.group(0)), lang=\"sw\"), text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def load_transcript(json_path: Path, verse: str) -> str:\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # convert PSA 19:1 -> PSA_019_001\n",
    "    get_verse = lambda x: x.split()[0] + \"_\" + x.split(\":\")[0].split()[1].zfill(3) + \"_\" + x.split(\":\")[1].zfill(3)\n",
    "    # filter by verse\n",
    "    transcript = [d[\"verseText\"] for d in data if get_verse(d[\"verseNumber\"]) == verse][0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = load_transcript(json_path, verse_id)\n",
    "verse = preprocess_verse(transcript)\n",
    "words = verse.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.MMS_FA\n",
    "model = bundle.get_model(with_star=False).to(device)\n",
    "LABELS = bundle.get_labels(star=None)\n",
    "DICTIONARY = bundle.get_dict(star=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_s = 15\n",
    "waveform, sr = torchaudio.load(audio_path)\n",
    "waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
    "sr = bundle.sample_rate\n",
    "chunk_size_frames = chunk_size_s * sr\n",
    "chunks = [waveform[:, i : i + chunk_size_frames] for i in range(0, waveform.shape[1], chunk_size_frames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for chunk in chunks:\n",
    "        if chunk.size(1) >= 400:\n",
    "            emission, _ = model(chunk.to(device))\n",
    "            emissions.append(emission)\n",
    "\n",
    "emission = torch.cat(emissions, dim=1)\n",
    "assert len(DICTIONARY) == emission.shape[2]\n",
    "num_frames = emission.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kwa sababu hii mimi paulo mfungwa wa kristo yesu kwa ajili yenu ninyi watu wa mataifa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.465915203094482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(emission, dim=2)\n",
    "greedy_prob = torch.max(probs, dim=-1).values.squeeze()\n",
    "greedy_log_probs = torch.sum(torch.log(greedy_prob)).cpu().numpy().item()\n",
    "greedy_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(emission, tokens):\n",
    "    targets = torch.tensor([tokens], dtype=torch.int32, device=device)\n",
    "    alignments, scores = F.forced_align(emission, targets, blank=0)\n",
    "\n",
    "    alignments, scores = alignments[0], scores[0]  # remove batch dimension for simplicity\n",
    "    scores = scores.exp()  # convert back to probability\n",
    "    return alignments, scores\n",
    "\n",
    "def compute_alignments(emission, transcript, dictionary):\n",
    "    tokens = [dictionary[char] for word in transcript for char in word]\n",
    "    _, scores = align(emission, tokens)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.359113693237305"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_probs = compute_alignments(emission, words, DICTIONARY)\n",
    "aligned_log_probs = torch.sum(torch.log(aligned_probs)).cpu().numpy().item()\n",
    "aligned_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11303391470923438"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_diff = (aligned_log_probs - greedy_log_probs) / num_frames\n",
    "probability_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
