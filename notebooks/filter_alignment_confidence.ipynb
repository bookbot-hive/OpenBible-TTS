{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-12.1.0\"\n",
    "os.environ[\"PATH\"] = f\"{os.environ['CUDA_HOME']}/bin:{os.environ['PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/lib64:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/lib:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/extras/CUPTI/lib64:{os.environ['LD_LIBRARY_PATH']}'\"\n",
    "os.environ[\"CUDAToolkit_ROOT_DIR\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDAToolkit_ROOT\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "\n",
    "os.environ[\"CUDA_TOOLKIT_ROOT_DIR\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_TOOLKIT_ROOT\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_BIN_PATH\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_PATH\"] = f\"{os.environ['CUDA_HOME']}\"\n",
    "os.environ[\"CUDA_INC_PATH\"] = f\"{os.environ['CUDA_HOME']}/targets/x86_64-linux\"\n",
    "os.environ[\"CFLAGS\"] = f\"-I{os.environ['CUDA_HOME']}/targets/x86_64-linux/include:{os.environ['CFLAGS']}\"\n",
    "os.environ[\"CUDAToolkit_TARGET_DIR\"] = f\"{os.environ['CUDA_HOME']}/targets/x86_64-linux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "audio_dir = Path(\"../outputs/openbible_swahili/TIT/\")\n",
    "audios = sorted(audio_dir.rglob(\"*/*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "from num2words import num2words\n",
    "\n",
    "def preprocess_verse(text: str) -> str:\n",
    "    text = unidecode(text)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r\"\\d+\", lambda x: num2words(int(x.group(0)), lang=\"sw\"), text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = [open(audio_path.with_suffix(\".txt\")).read() for audio_path in audios]\n",
    "verses = [preprocess_verse(v) for v in transcripts]\n",
    "words = [verse.split() for verse in verses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.MMS_FA\n",
    "model = bundle.get_model(with_star=False).to(device)\n",
    "LABELS = bundle.get_labels(star=None)\n",
    "DICTIONARY = bundle.get_dict(star=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = [torchaudio.load(audio_path) for audio_path in audios]\n",
    "resampled_waveforms = [torchaudio.functional.resample(waveform, sr, bundle.sample_rate).squeeze() for (waveform, sr) in waveforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "batch_size = 16\n",
    "waveform_lengths = [waveform.shape[0] for waveform in resampled_waveforms]\n",
    "waveforms_batches = [\n",
    "    pad_sequence(resampled_waveforms[i : i + batch_size], batch_first=True, padding_value=0) # (batch_size, max_batch_frame_length)\n",
    "    for i in range(0, len(resampled_waveforms), batch_size)\n",
    "]\n",
    "waveform_lengths_batches = [torch.tensor(waveform_lengths[i : i + batch_size], dtype=torch.int64) for i in range(0, len(waveform_lengths), batch_size)]\n",
    "words_batches = [words[i: i + batch_size] for i in range(0, len(words), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(emission, tokens):\n",
    "    targets = torch.tensor([tokens], dtype=torch.int32, device=device)\n",
    "    alignments, scores = F.forced_align(emission, targets, blank=0)\n",
    "\n",
    "    alignments, scores = alignments[0], scores[0]  # remove batch dimension for simplicity\n",
    "    scores = scores.exp()  # convert back to probability\n",
    "    return alignments, scores\n",
    "\n",
    "def compute_alignments(emission, transcript, dictionary):\n",
    "    tokens = [dictionary[char] for word in transcript for char in word]\n",
    "    _, scores = align(emission, tokens)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "3it [00:05,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "probability_diffs = []\n",
    "\n",
    "for waveform_batch, waveform_lengths_batch, words_batch in tqdm(zip(waveforms_batches, waveform_lengths_batches, words_batches)):\n",
    "    with torch.inference_mode():\n",
    "        emission, lengths = model(waveform_batch.to(device), waveform_lengths_batch.to(device))  # (batch_size, max_batch_frame_length, num_labels)\n",
    "\n",
    "    assert len(DICTIONARY) == emission.shape[2]\n",
    "    \n",
    "    greedy_log_probs, aligned_log_probs = [], []\n",
    "    \n",
    "    for i, length in zip(range(len(waveform_batch)), lengths):\n",
    "        prob = torch.softmax(emission[i, :length, :].unsqueeze(dim=0), dim=-1) # (1, frame_length, num_labels)\n",
    "        greedy_prob = torch.max(prob, dim=-1).values  # (1, frame_length)\n",
    "        greedy_log_prob = torch.sum(torch.log(greedy_prob), dim=-1).cpu().numpy().item()  # (1,)\n",
    "        greedy_log_probs.append(greedy_log_prob)\n",
    "\n",
    "    for i, length, words in zip(range(len(waveform_batch)), lengths, words_batch):\n",
    "        aligned_prob = compute_alignments(emission[i, :length, :].unsqueeze(dim=0), words, DICTIONARY).squeeze() # (1, max_batch_frame_length)\n",
    "        aligned_log_prob = torch.sum(torch.log(aligned_prob), dim=-1).cpu().numpy().item()  # (1,)\n",
    "        aligned_log_probs.append(aligned_log_prob)\n",
    "    \n",
    "    probability_diff = (np.array(aligned_log_probs) - np.array(greedy_log_probs)) / lengths.cpu().numpy()\n",
    "    probability_diffs.append(probability_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "probability_diff = np.concatenate(probability_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.40528992e-02, -1.89833464e-03, -4.03621128e-02, -1.36629125e-02,\n",
       "       -5.36187735e-02, -6.03735537e-03, -1.01689745e-04, -8.08676382e-03,\n",
       "       -6.20300734e-03, -6.25828451e-03, -5.41766485e-03, -1.59862852e-02,\n",
       "       -5.63826928e-03, -1.07708556e-02, -7.76849784e-04, -1.30411468e-02,\n",
       "       -6.76120129e-01, -1.92474574e-02, -6.72453406e-04, -6.07647047e-03,\n",
       "       -2.00812953e-02, -1.85933865e-01, -1.22369718e-01, -2.13108201e-01,\n",
       "        1.05963813e-08, -1.14707111e-01, -3.69093183e-01, -8.67848460e-02,\n",
       "       -1.82920774e-02, -6.08356884e-02, -3.99380892e-02, -1.32169939e-02,\n",
       "       -1.43288424e-02, -1.52013000e-03, -4.69207404e-02, -1.00355958e-02,\n",
       "       -1.16333925e-02, -9.08226194e-03, -6.26507503e-03, -1.00488384e-02,\n",
       "       -3.30925228e-03, -1.43456774e-02, -1.82007898e-03, -3.48143525e-02,\n",
       "       -2.52966684e-01, -9.34417964e-03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16, 23, 26, 44]),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(probability_diff <= -.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
